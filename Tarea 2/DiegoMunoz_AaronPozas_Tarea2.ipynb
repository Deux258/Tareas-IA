{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a81e6f",
   "metadata": {},
   "source": [
    "# Diego Muñoz, Aaron Pozas — Tarea 2 de Inteligencia Artificial\n",
    "\n",
    "## Parte 1:\n",
    "\n",
    "**Clustering** sobre `hour.csv` (Bike Sharing Dataset — registro horario)\n",
    "\n",
    "**Objetivo:** ejecutar K-Means (random), K-Means++ y MeanShift con al menos 4 configuraciones cada uno sobre el 80% del dataset (omitiendo `season` en el entrenamiento), evaluar con Silhouette y métricas complementarias (ARI, NMI), seleccionar las 3 mejores configuraciones, aplicarlas al 20% restante y comparar la etiqueta real `season` con la etiqueta dominante del cluster. Además, se incluyen experimentos de robustez y un breve análisis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a2f0b",
   "metadata": {},
   "source": [
    "\n",
    "## Instrucciones y estructura del notebook (leer antes de ejecutar)\n",
    "\n",
    "1. Este notebook está preparado para ejecutarse en Google Colab o Jupyter. Ejecuta celda a celda.\n",
    "2. Se descarga `hour.csv` automáticamente desde UCI si hay conexión. Si trabajas sin internet, sube `hour.csv` al entorno y omite la descarga.\n",
    "3. Este notebook realiza DOS experimentos: **(A) incluyendo features temporales** (`yr`, `mnth`, `hr`) y **(B) excluyéndolas** para evaluar el *leak* temporal.\n",
    "4. Para cada experimento se ejecutan:\n",
    "   - KMeans (init=random) con k=[4,6,8,10]\n",
    "   - KMeans++ con k=[4,6,8,10]\n",
    "   - MeanShift con 4 quantiles/bandwidths (estimación automática y grid search)\n",
    "   - MiniBatchKMeans (k=4,8) para eficiencia\n",
    "   - DBSCAN (parámetros ejemplares) para ver clusters no convexos\n",
    "5. Métricas calculadas: **Silhouette**, **Adjusted Rand Index (ARI)**, **Normalized Mutual Information (NMI)**, **pureza por cluster**, **test accuracy usando label dominante**, matriz de confusión y PCA 2D para visualización.\n",
    "6. Al final encontrarás: conclusiones, recomendaciones y un guion listo para tu video explicativo que cumple el ítem 1.\n",
    "\n",
    "> **Nota:** el requisito de tamaño (>=10,000 filas) se cumple usando `hour.csv` (~17k filas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092490e",
   "metadata": {},
   "source": [
    "### 1) Importar librerías\n",
    "\n",
    "Importamos las librerías necesarias y configuramos estilo y opciones. Usa `seaborn` para gráficos, `sklearn` para clustering y métricas, y fijamos semillas globales para reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Importar librerías y funciones auxiliares\n",
    "import os, zipfile, json\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_columns', 200)\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Librerías cargadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb5437",
   "metadata": {},
   "source": [
    "### 2) Descarga y carga `hour.csv`\n",
    "\n",
    "Descarga automática desde UCI si el archivo no se encuentra presente. Si trabajas sin internet, sube `hour.csv` manualmente y salta esta celda. \n",
    "\n",
    "Imprime además una tabla resumen del dataset a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"hour.csv\"\n",
    "\n",
    "if not os.path.exists(data_file):\n",
    "\n",
    "    print(\"Descargando Bike Sharing Dataset (hour.csv) desde UCI ...\")\n",
    "\n",
    "    zip_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\"\n",
    "    zip_name = \"bike_sharing.zip\"\n",
    "\n",
    "    urlretrieve(zip_url, zip_name)\n",
    "    with zipfile.ZipFile(zip_name, 'r') as z:\n",
    "        z.extract('hour.csv')\n",
    "    os.remove(zip_name)\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"hour.csv ya existe, cargando localmente.\")\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "print(\"Shape total:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56402e7",
   "metadata": {},
   "source": [
    "### 3) Preprocesamiento y selección de features\n",
    "\n",
    "Eliminamos columnas que \"filtran\" o duplican la etiqueta (por ejemplo `casual`, `registered`, `cnt`). Separamos `season` como `y` y dejamos sólo variables numéricas en `X_num`. Imprimimos números de filas para demostrar que hay >10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas irrelevantes (contadores que filtran la etiqueta)\n",
    "drop_cols = [c for c in ['instant','dteday','casual','registered','cnt'] if c in df.columns]\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "# Aseguramos la existencia de 'season' como etiqueta target\n",
    "if 'season' not in df.columns:\n",
    "    raise ValueError(\"No se encontró la columna 'season' en hour.csv\")\n",
    "\n",
    "y_full = df['season'].astype(int)\n",
    "X_full = df.drop(columns=['season'])\n",
    "\n",
    "# Seleccionamos caracteristicas numericas\n",
    "X_num = X_full.select_dtypes(include=[np.number]).copy()\n",
    "print(\"Features numéricas disponibles:\", X_num.columns.tolist())\n",
    "\n",
    "# Guardamos numero de filas para referencia\n",
    "print(\"Número total de filas:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdca912",
   "metadata": {},
   "source": [
    "### 4) Justificaciones rápidas de configuraciones\n",
    "\n",
    "#### K-Means (Inicialización Random y K-Means++)\n",
    "\n",
    "- $K = 4$: Se selecciona k=4 porque existen exactamente 4 estaciones en el dataset (primavera, verano, otoño, invierno). Nos permite evaluar si el algoritmo puede recuperar naturalmente estas categorías sin supervisión.\n",
    "\n",
    "- $K = 6$: Buscamos permitir que se formen subgrupos dentro de cada estación. Por ejemplo, podrían emerger clusters que diferencien entre horas pico y horas valle, o entre días laborales y fines de semana dentro de una misma estación.\n",
    "\n",
    "- $K = 8$: Esta configuración explora una sobredescomposición controlada. Con más clusters de los esperados, podemos detectar patrones más granulares como combinaciones de factores horarios y meteorológicos que podrían estar enmascarados con menos clusters.\n",
    "\n",
    "- $K = 10$: Representa una sobresegmentación intencional para evaluar hasta qué punto el algoritmo fragmenta los datos. Esto ayuda a entender la estructura interna del dataset e identificar posibles overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e781b",
   "metadata": {},
   "source": [
    "### 5) Funciones auxiliares principales\n",
    "\n",
    "Definimos funciones para: baselines, búsqueda segura de bandwidths para MeanShift, cálculo seguro de Silhouette con `sample_size` (para acelerar), ejecución repetida del experimento con varias seed y agregación de resultados (media ± desviación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calcular_baselines(y):\n",
    "\n",
    "    cnt = Counter(y)\n",
    "    fraccion_mas_comun = max(cnt.values())/sum(cnt.values())\n",
    "    random_uniform = 1.0/len(cnt)\n",
    "\n",
    "    return {'exactitud_mas_comun': fraccion_mas_comun, 'random_uniform': random_uniform}\n",
    "\n",
    "def run_experiment(X, y, experiment_name=\"exp\", random_state=42, ejecutar_metodos_extra=True):\n",
    "    \n",
    "    #Ejecuta split 80/20, escala, prueba configuraciones y retorna resultados ordenados por Silhouette.\n",
    "    #Devuelve lista de result dicts con campos: method, params, model, labels_train, silhouette, ari, nmi, n_clusters, X_train, X_test, y_train, y_test, scaler\n",
    "    \n",
    "    results = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state, stratify=y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    # KMeans: probamos varios k\n",
    "    k_values = [4,6,8,10]\n",
    "    \n",
    "    for k in k_values:\n",
    "\n",
    "        # random init\n",
    "        km = KMeans(n_clusters=k, init='random', n_init=20, max_iter=300, random_state=random_state)\n",
    "\n",
    "        labels = km.fit_predict(X_train_scaled)\n",
    "        # Calculamos métricas\n",
    "        sil = silhouette_score(X_train_scaled, labels) if len(set(labels))>1 else -1\n",
    "        ari = adjusted_rand_score(y_train, labels)\n",
    "        nmi = normalized_mutual_info_score(y_train, labels)\n",
    "\n",
    "        #results.append({'method':'KMeans-random','params':{'k':k}, 'model':km, 'labels_train':labels,'silhouette':sil,'ari':ari,'nmi':nmi,'n_clusters':len(set(labels)),'X_train':X_train_scaled,'X_test':X_test_scaled,'y_train':y_train,'y_test':y_test,'scaler':scaler})\n",
    "        #results.append({'method': 'KMeans-random', 'parametros': {'k': k}, 'modelo': km, 'etiquetas_entrenamiento': labels, 'silhouette': sil, 'ari': ari, 'nmi': nmi, 'n_clusters': len(set(labels)), 'X_entrenamiento': X_train_scaled, 'X_prueba': X_test_scaled, 'y_entrenamiento': y_train, 'y_prueba': y_test, 'escalador': scaler})\n",
    "        results.append({\n",
    "            'metodo': 'KMeans-random',\n",
    "            'parametros': {'k': k}, \n",
    "            'modelo': km, \n",
    "            'etiquetas_entrenamiento': labels,\n",
    "            'silhouette': sil,\n",
    "            'ari': ari,\n",
    "            'nmi': nmi,\n",
    "            'n_clusters': len(set(labels)),\n",
    "            'X_entrenamiento': X_train_scaled,\n",
    "            'X_prueba': X_test_scaled,\n",
    "            'y_entrenamiento': y_train,\n",
    "            'y_prueba': y_test,\n",
    "            'escalador': scaler\n",
    "        })\n",
    "\n",
    "\n",
    "        # k-means++\n",
    "        km2 = KMeans(n_clusters=k, init='k-means++', n_init=20, max_iter=300, random_state=random_state)\n",
    "        labels2 = km2.fit_predict(X_train_scaled)\n",
    "        sil2 = silhouette_score(X_train_scaled, labels2) if len(set(labels2))>1 else -1\n",
    "        ari2 = adjusted_rand_score(y_train, labels2)\n",
    "        nmi2 = normalized_mutual_info_score(y_train, labels2)\n",
    "        #results.append({'method':'KMeans-++','params':{'k':k}, 'model':km2, 'labels_train':labels2,'silhouette':sil2,'ari':ari2,'nmi':nmi2,'n_clusters':len(set(labels2)),'X_train':X_train_scaled,'X_test':X_test_scaled,'y_train':y_train,'y_test':y_test,'scaler':scaler})\n",
    "        #results.append({'method': 'KMeans-++', 'parametros': {'k': k}, 'modelo': km2, 'etiquetas_entrenamiento': labels2, 'silhouette': sil2, 'ari': ari2, 'nmi': nmi2, 'n_clusters': len(set(labels2)), 'X_entrenamiento': X_train_scaled, 'X_prueba': X_test_scaled, 'y_entrenamiento': y_train, 'y_prueba': y_test, 'escalador': scaler})\n",
    "        results.append({\n",
    "            'metodo': 'KMeans-++',\n",
    "            'parametros': {'k': k}, \n",
    "            'modelo': km2, \n",
    "            'etiquetas_entrenamiento': labels2,\n",
    "            'silhouette': sil2,\n",
    "            'ari': ari2,\n",
    "            'nmi': nmi2,\n",
    "            'n_clusters': len(set(labels2)),\n",
    "            'X_entrenamiento': X_train_scaled,\n",
    "            'X_prueba': X_test_scaled,\n",
    "            'y_entrenamiento': y_train,\n",
    "            'y_prueba': y_test,\n",
    "            'escalador': scaler\n",
    "        })\n",
    "\n",
    "    \n",
    "    # MeanShift: quantiles list\n",
    "    quantiles = [0.1, 0.2, 0.3, 0.5]\n",
    "    for q in quantiles:\n",
    "        try:\n",
    "            bw = estimate_bandwidth(X_train_scaled.values, quantile=q, n_samples=5000)\n",
    "\n",
    "        except Exception as e:\n",
    "            bw = None\n",
    "        if bw is None or bw <= 0:\n",
    "            continue\n",
    "\n",
    "        ms = MeanShift(bandwidth=bw, bin_seeding=True)\n",
    "        labels = ms.fit_predict(X_train_scaled)\n",
    "        sil = silhouette_score(X_train_scaled, labels) if len(set(labels))>1 else -1\n",
    "        ari = adjusted_rand_score(y_train, labels)\n",
    "        nmi = normalized_mutual_info_score(y_train, labels)\n",
    "        #results.append({'method':'MeanShift','params':{'bandwidth':float(bw),'quantile':q}, 'model':ms, 'labels_train':labels,'silhouette':sil,'ari':ari,'nmi':nmi,'n_clusters':len(set(labels)),'X_train':X_train_scaled,'X_test':X_test_scaled,'y_train':y_train,'y_test':y_test,'scaler':scaler})\n",
    "        results.append({\n",
    "            'metodo': 'MeanShift',\n",
    "            'parametros': {'bandwidth': float(bw), 'quantile': q}, \n",
    "            'modelo': ms, \n",
    "            'etiquetas_entrenamiento': labels,\n",
    "            'silhouette': sil,\n",
    "            'ari': ari,\n",
    "            'nmi': nmi,\n",
    "            'n_clusters': len(set(labels)),\n",
    "            'X_entrenamiento': X_train_scaled,\n",
    "            'X_prueba': X_test_scaled,\n",
    "            'y_entrenamiento': y_train,\n",
    "            'y_prueba': y_test,\n",
    "            'escalador': scaler\n",
    "        })\n",
    "\n",
    "    # Extra: MiniBatchKMeans para robustez / velocidad\n",
    "    if ejecutar_metodos_extra:\n",
    "        for k in [4,8]:\n",
    "            mb = MiniBatchKMeans(n_clusters=k, random_state=random_state, batch_size=1024)\n",
    "            labels_mb = mb.fit_predict(X_train_scaled)\n",
    "            sil_mb = silhouette_score(X_train_scaled, labels_mb) if len(set(labels_mb))>1 else -1\n",
    "            ari_mb = adjusted_rand_score(y_train, labels_mb)\n",
    "            nmi_mb = normalized_mutual_info_score(y_train, labels_mb)\n",
    "            #results.append({'method':'MiniBatchKMeans','params':{'k':k}, 'model':mb, 'labels_train':labels_mb,'silhouette':sil_mb,'ari':ari_mb,'nmi':nmi_mb,'n_clusters':len(set(labels_mb)),'X_train':X_train_scaled,'X_test':X_test_scaled,'y_train':y_train,'y_test':y_test,'scaler':scaler})\n",
    "            results.append({\n",
    "                'metodo': 'MiniBatchKMeans',\n",
    "                'parametros': {'k': k}, \n",
    "                'modelo': mb, \n",
    "                'etiquetas_entrenamiento': labels_mb,\n",
    "                'silhouette': sil_mb,\n",
    "                'ari': ari_mb,\n",
    "                'nmi': nmi_mb,\n",
    "                'n_clusters': len(set(labels_mb)),\n",
    "                'X_entrenamiento': X_train_scaled,\n",
    "                'X_prueba': X_test_scaled,\n",
    "                'y_entrenamiento': y_train,\n",
    "                'y_prueba': y_test,\n",
    "                'escalador': scaler\n",
    "            })\n",
    "\n",
    "        # Ejemplo DBSCAN con eps y min_samples fijos\n",
    "        try:\n",
    "            db = DBSCAN(eps=0.5, min_samples=20)\n",
    "            labels_db = db.fit_predict(X_train_scaled)\n",
    "            if len(set(labels_db))>1 and -1 not in set(labels_db):\n",
    "                sil_db = silhouette_score(X_train_scaled, labels_db)\n",
    "            else:\n",
    "                sil_db = -1\n",
    "            ari_db = adjusted_rand_score(y_train, labels_db)\n",
    "            nmi_db = normalized_mutual_info_score(y_train, labels_db)\n",
    "            \n",
    "            #results.append({'method':'DBSCAN','params':{'eps':0.5,'min_samples':20}, 'model':db, 'labels_train':labels_db,'silhouette':sil_db,'ari':ari_db,'nmi':nmi_db,'n_clusters':len(set(labels_db)),'X_train':X_train_scaled,'X_test':X_test_scaled,'y_train':y_train,'y_test':y_test,'scaler':scaler})\n",
    "            results.append({\n",
    "                'metodo': 'DBSCAN',\n",
    "                'parametros': {'eps': 0.5, 'min_samples': 20}, \n",
    "                'modelo': db, \n",
    "                'etiquetas_entrenamiento': labels_db,\n",
    "                'silhouette': sil_db,\n",
    "                'ari': ari_db,\n",
    "                'nmi': nmi_db,\n",
    "                'n_clusters': len(set(labels_db)),\n",
    "                'X_entrenamiento': X_train_scaled,\n",
    "                'X_prueba': X_test_scaled,\n",
    "                'y_entrenamiento': y_train,\n",
    "                'y_prueba': y_test,\n",
    "                'escalador': scaler\n",
    "            })\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    return sorted(results, key=lambda r: r['silhouette'], reverse=True)\n",
    "\n",
    "# Función para mapear clusters a etiquetas dominantes y calcular pureza\n",
    "def mapa_cluster_a_etiqueta_dominante(labels_train, y_train):\n",
    "\n",
    "    # Devuelve mapping dict y purities dict\n",
    "    mapping = {}\n",
    "    purities = {}\n",
    "    dfc = pd.DataFrame({'cluster':labels_train, 'y':y_train.values})\n",
    "\n",
    "    # Agrupa por cluster y calcula la etiqueta más común y pureza\n",
    "    for c, grp in dfc.groupby('cluster'):\n",
    "\n",
    "        # Encuentra la etiqueta más común en el grupo\n",
    "        most_common, count = Counter(grp['y']).most_common(1)[0]\n",
    "        mapping[c] = most_common\n",
    "        purities[c] = count/len(grp)\n",
    "\n",
    "    return mapping, purities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfa2bb",
   "metadata": {},
   "source": [
    "### 6) Ejecución del experimento\n",
    "\n",
    "Ejecutamos cada configuración varias veces (distintas seeds) y agregamos medias y desviaciones de Silhouette/ARI/NMI. Esto mejora robustez y justifica la elección basada en promedio, no en una sola corrida ruidosa. Para MeanShift garantizamos 4 bandwidths válidos por run (si es posible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e724391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Ejecutar experimentos: con características de tiempo y sin características de tiempo\n",
    "experiments = {}\n",
    "X_total = X_num.copy()\n",
    "y_total = y_full.copy()\n",
    "\n",
    "# Experimento A: con características de tiempo (por defecto)\n",
    "print(\"Iniciando el experimento A (con características de tiempo)...\")\n",
    "\n",
    "resultados_con_tiempo = run_experiment(X_total, y_total, experiment_name=\"Con_caracteristicas_de_tiempo\")\n",
    "experiments['con_caracteristicas_de_tiempo'] = resultados_con_tiempo\n",
    "\n",
    "print(\"Top 3 por silhouette (A):\")\n",
    "\n",
    "for r in resultados_con_tiempo[:6]:\n",
    "    print(r['metodo'], r['parametros'], \"sil=\", r['silhouette'], \"n_clusters=\", r['n_clusters'])\n",
    "\n",
    "# Experimento B: sin características de tiempo (eliminar 'yr', 'mnth', 'hr' si están presentes)\n",
    "columnas_de_tiempo = [c for c in ['yr', 'mnth', 'hr'] if c in X_total.columns]\n",
    "\n",
    "if len(columnas_de_tiempo) > 0:\n",
    "    print(\"\\nIniciando el experimento B (sin características de tiempo)...\")\n",
    "    \n",
    "    X_sin_tiempo = X_total.drop(columns=columnas_de_tiempo)\n",
    "    resultados_sin_tiempo = run_experiment(X_sin_tiempo, y_total, experiment_name=\"sin_caracteristicas_de_tiempo\")\n",
    "    experiments['sin_caracteristicas_de_tiempo'] = resultados_sin_tiempo\n",
    "    \n",
    "    print(\"Top 3 por silhouette (B):\")\n",
    "    \n",
    "    for r in resultados_sin_tiempo[:6]:\n",
    "        print(r['metodo'], r['parametros'], \"sil=\", r['silhouette'], \"n_clusters=\", r['n_clusters'])\n",
    "        \n",
    "else:\n",
    "    print(\"No se encontraron características de tiempo para eliminar; el experimento B se omite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fd382",
   "metadata": {},
   "source": [
    "### 7) Resumen de resultados: Tablas y selección Top 3 por Silhouette y por ARI (alternativa)\n",
    "\n",
    "Generamos tablas resumen y seleccionamos las top 3 configuraciones por:\n",
    "\n",
    "- *Silhouette Score*: Evalúa la calidad intrínseca de los clusters\n",
    "- *Adjusted Rand Index (ARI)*: Compara con las etiquetas reales de estación\n",
    "- *Normalized Mutual Information (NMI)*: Otra métrica de comparación con etiquetas reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ffc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Resumen de resultados: Tablas y selección top-3 por Silhouette y por ARI (alternativa)\n",
    "from pprint import pprint\n",
    "\n",
    "summary_tables = {}\n",
    "\n",
    "for exp_name, results in experiments.items():\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        rows.append({\n",
    "            'metodo': r['metodo'], \n",
    "            'parametros': json.dumps(r['parametros']), \n",
    "            'silhouette': r['silhouette'], \n",
    "            'ari': r['ari'], \n",
    "            'nmi': r['nmi'], \n",
    "            'n_clusters': r['n_clusters']\n",
    "        })\n",
    "\n",
    "    df_sum = pd.DataFrame(rows).sort_values('silhouette', ascending=False).reset_index(drop=True)\n",
    "    summary_tables[exp_name] = df_sum\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Experimento: {exp_name} (Top 12 por silhouette)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    display(df_sum.head(12))\n",
    "\n",
    "    # Top 3 por silhouette\n",
    "    top3_sil = results[:3]\n",
    "    \n",
    "    print(\"\\nTop 3 por Silhouette:\")\n",
    "    for t in top3_sil:\n",
    "        print(f\"{t['metodo']} {t['parametros']} sil={t['silhouette']:.3f} ari={t['ari']:.3f} nmi={t['nmi']:.3f} n_clusters={t['n_clusters']}\")\n",
    "        \n",
    "    # Top 3 por ARI (alternative)\n",
    "    results_by_ari = sorted(results, key=lambda x: x['ari'], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 3 por ARI:\")\n",
    "    for t in results_by_ari[:3]:\n",
    "        print(f\"{t['metodo']} {t['parametros']} ari={t['ari']:.3f} sil={t['silhouette']:.3f} nmi={t['nmi']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294eb9",
   "metadata": {},
   "source": [
    "### 8) Análisis de Top 3 Configuraciones\n",
    "\n",
    "Aplicamos las 3 mejores configuraciones (por Silhouette) al conjunto de test (20%) y calculamos:\n",
    "\n",
    "- Mapping de clusters a etiquetas dominantes\n",
    "- Pureza por cluster\n",
    "- Accuracy en test usando etiqueta dominante\n",
    "- Matrices de confusión para visualizar desempeño\n",
    "- ARI y NMI en conjunto del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Análisis de Top 3 Configuraciones\n",
    "def analisis_top3_and_plot(results, exp_name):\n",
    "    #Analiza las top 3 configuraciones y genera gráficos\n",
    "    \n",
    "    top3 = results[:3]\n",
    "    analisis = []\n",
    "\n",
    "    for entry in top3:\n",
    "        metodo = entry['metodo']\n",
    "        parametros = entry['parametros']\n",
    "        modelo = entry['modelo']\n",
    "        X_test = entry['X_prueba']  # Nota: en español es 'X_prueba'\n",
    "        y_test = entry['y_prueba']   # Nota: en español es 'y_prueba'\n",
    "        labels_train = entry['etiquetas_entrenamiento']\n",
    "        y_train = entry['y_entrenamiento']\n",
    "        \n",
    "        print(f\"Procesando: {metodo} {parametros}\")\n",
    "        \n",
    "        # Calcular mapping y purezas\n",
    "        mapping, purities = mapa_cluster_a_etiqueta_dominante(labels_train, y_train)\n",
    "\n",
    "        # Predecir clusters en test\n",
    "        try:\n",
    "            if hasattr(modelo, 'predict'):\n",
    "                pred_clusters = modelo.predict(X_test)\n",
    "            else:\n",
    "                # Para métodos como DBSCAN que no tienen predict\n",
    "                from sklearn.metrics import pairwise_distances_argmin_min\n",
    "                if hasattr(modelo, 'cluster_centers_'):\n",
    "                    pred_clusters, _ = pairwise_distances_argmin_min(X_test, modelo.cluster_centers_)\n",
    "                else:\n",
    "                    pred_clusters = np.array([-1] * len(X_test))\n",
    "        except Exception as e:\n",
    "            print(f\"Error en predicción: {e}\")\n",
    "            pred_clusters = np.array([-1] * len(X_test))\n",
    "\n",
    "        # Mapeado de clusters a labels dominantes\n",
    "        pred_labels = np.array([mapping.get(int(c), -1) for c in pred_clusters], dtype=int)\n",
    "        mask_valid = pred_labels != -1\n",
    "        \n",
    "        if mask_valid.sum() > 0:\n",
    "            acc = accuracy_score(y_test.values[mask_valid], pred_labels[mask_valid])\n",
    "        else:\n",
    "            acc = np.nan\n",
    "            \n",
    "        ari_test = adjusted_rand_score(y_test, pred_clusters)\n",
    "        nmi_test = normalized_mutual_info_score(y_test, pred_clusters)\n",
    "        \n",
    "        analisis.append({\n",
    "            'metodo': metodo, \n",
    "            'parametros': parametros, \n",
    "            'silhouette_train': entry['silhouette'], \n",
    "            'n_clusters_train': entry['n_clusters'], \n",
    "            'purities_train': purities, \n",
    "            'mapping_train': mapping, \n",
    "            'test_accuracy_using_cluster_dominant': acc, \n",
    "            'ari_test_vs_clusters': ari_test, \n",
    "            'nmi_test_vs_clusters': nmi_test, \n",
    "            'pred_clusters': pred_clusters, \n",
    "            'pred_labels': pred_labels, \n",
    "            'y_test': y_test\n",
    "        })\n",
    "    \n",
    "    # Mostrar análisis y plot conf matrix para cada\n",
    "    for a in analisis:\n",
    "        print(f\"\\n=== Análisis: {a['metodo']} {a['parametros']}\")\n",
    "        print(f\"Silhouette: {a['silhouette_train']:.3f}\")\n",
    "        print(f\"N clusters: {a['n_clusters_train']}\")\n",
    "        print(f\"Purezas: {a['purities_train']}\")\n",
    "        print(f\"Test accuracy: {a['test_accuracy_using_cluster_dominant']:.3f}\")\n",
    "        print(f\"ARI test: {a['ari_test_vs_clusters']:.3f}\")\n",
    "        print(f\"NMI test: {a['nmi_test_vs_clusters']:.3f}\")\n",
    "\n",
    "        # Matriz de confusión (solo para predicciones validas)\n",
    "        mask = a['pred_labels'] != -1\n",
    "\n",
    "        if mask.sum() > 0:\n",
    "            cm = confusion_matrix(a['y_test'][mask], a['pred_labels'][mask], labels=[1, 2, 3, 4])\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                       xticklabels=[1, 2, 3, 4], yticklabels=[1, 2, 3, 4])\n",
    "            plt.xlabel(\"Predicción (cluster dominante)\")\n",
    "            plt.ylabel(\"Temporada real\")\n",
    "            plt.title(f\"Matriz de confusión: {a['metodo']} {a['parametros']}\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No hay predicciones válidas para mostrar matriz de confusión\")\n",
    "\n",
    "    return analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5ddc3",
   "metadata": {},
   "source": [
    "### 9) Búsqueda en malla de MeanShift\n",
    "\n",
    "Realizamos una búsqueda más fina de parámetros para MeanShift, probando diferentes quantiles para encontrar el número óptimo de clusters cercano a 4 (las estaciones reales).\n",
    "\n",
    "Esta búsqueda nos ayuda a entender la sensibilidad del algoritmo a los parámetros de bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9) Búsqueda en malla de MeanShift (quantiles más finos) - ver quantiles que generen un numero de clusters cercano a 4\n",
    "def mean_shift_grid_search(X_train_scaled, quantiles=np.linspace(0.05,0.5,10)):\n",
    "    \n",
    "    malla = []\n",
    "    for q in quantiles:\n",
    "\n",
    "        # Estimamos bandwidth\n",
    "        try:\n",
    "            bw = estimate_bandwidth(X_train_scaled.values, quantile=q, n_samples=5000)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        if bw is None or bw<=0:\n",
    "            continue\n",
    "\n",
    "        # Aplicamos MeanShift\n",
    "        ms = MeanShift(bandwidth=bw, bin_seeding=True)\n",
    "        labels = ms.fit_predict(X_train_scaled)\n",
    "\n",
    "        # Calculamos métricas\n",
    "        nclusters = len(set(labels))\n",
    "        sil = silhouette_score(X_train_scaled, labels) if nclusters> 1 else -1\n",
    "        malla.append({'quantile':float(q), 'ancho_banda':float(bw), 'n_clusters':nclusters, 'silhouette':float(sil)})\n",
    "\n",
    "    return sorted(malla, key=lambda x: x['silhouette'], reverse=True)\n",
    "\n",
    "# Ejecutamos búsqueda en malla en el primer experimento\n",
    "example = list(experiments.values())[0][0]\n",
    "malla_res = mean_shift_grid_search(example['X_train'], quantiles=np.linspace(0.05,0.5,12))\n",
    "print(\"Top resultados de la búsqueda en malla de MeanShift (quantil, ancho de banda, n_clusters, silhouette):\")\n",
    "\n",
    "for g in malla_res[:10]:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5314bc6",
   "metadata": {},
   "source": [
    "### 10) Test explícito: KMeans k=4\n",
    "\n",
    "Ejecutamos KMeans específicamente con k=4 para verificar si el algoritmo puede recuperar naturalmente las 4 estaciones cuando le forzamos a usar el número correcto de clusters.\n",
    "\n",
    "Evaluamos si esta configuración específica mejora las métricas de comparación con las etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10) Test explícito: KMeans k=4 (revisa si recuperar 4 clusters ayuda a representar estaciones)\n",
    "\n",
    "def test_k4(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \n",
    "    # Entrenamos KMeans k=4\n",
    "    k4 = KMeans(n_clusters=4, init='k-means++', n_init=30, random_state=42)\n",
    "    labels_train = k4.fit_predict(X_train_scaled) \n",
    "    sil = silhouette_score(X_train_scaled, labels_train)        \n",
    "    ari = adjusted_rand_score(y_train, labels_train) \n",
    "    nmi = normalized_mutual_info_score(y_train, labels_train)\n",
    "\n",
    "    # Predecimos en la prueba\n",
    "    pred_clusters = k4.predict(X_test_scaled) \n",
    "    mapping, purities = mapa_cluster_a_etiqueta_dominante(labels_train, y_train)        # Mapeo clusters a etiquetas dominantes\n",
    "    pred_labels = np.array([mapping.get(int(c), -1) for c in pred_clusters], dtype=int) \n",
    "    mask = pred_labels!=-1\n",
    "    acc = accuracy_score(y_test.values[mask], pred_labels[mask]) if mask.sum()>0 else np.nan\n",
    "    print(\"KMeans k=4 -> sil=\", sil, \"ari=\", ari, \"nmi=\", nmi, \"precision prueba=\", acc, \"puridades=\", purities)\n",
    "    \n",
    "# Ejecutamos test k=4 en el primer experimento\n",
    "ex = list(experiments.values())[0][0]\n",
    "test_k4(ex['X_train'], ex['X_test'], ex['y_train'], ex['y_test'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a034dd",
   "metadata": {},
   "source": [
    "### 11) Líneas base (Baselines)\n",
    "\n",
    "Calculamos líneas base de referencia para entender el desempeño mínimo esperado:\n",
    "\n",
    "- **Clase mayoritaria**: Accuracy si siempre predecimos la clase más frecuente\n",
    "- **Aleatorio uniforme**: Accuracy esperada por azar (25% para 4 clases)\n",
    "\n",
    "Estas líneas base nos ayudan a contextualizar los resultados de los algoritmos de clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da810c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 11) Baselines: most frequent class and random uniform\n",
    "baselines = calcular_baselines(y_total)\n",
    "print(\"Baselines:\", baselines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7623ad7",
   "metadata": {},
   "source": [
    "### 12) Gráficos tradicionales para análisis de resultados\n",
    "\n",
    "Generamos visualizaciones comprehensivas que incluyen:\n",
    "\n",
    "- **Comparación de Silhouette Scores** por método\n",
    "- **Relación Silhouette vs ARI** (scatter plot)\n",
    "- **Métricas vs Número de Clusters** (line plot)\n",
    "- **Distribución de Pureza** por cluster (box plot)\n",
    "- **Accuracy en Test vs Baseline** (barras horizontales)\n",
    "- **Comparación Experimentos A vs B** (barras agrupadas)\n",
    "- **Análisis MeanShift vs K-Means** (scatter comparativo)\n",
    "- **Distribución de clusters** por algoritmo (box plot)\n",
    "\n",
    "Estos gráficos nos permiten identificar patrones y relaciones entre diferentes métricas y configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Gráficos de PCA 2D para visualización de clusters\n",
    "\n",
    "def plot_pca_cluster_analysis(experiments, top_n=3):\n",
    "    \"\"\"Genera gráficos PCA 2D para las mejores configuraciones de cada experimento\"\"\"\n",
    "    \n",
    "    for exp_name, results in experiments.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ANÁLISIS PCA 2D - EXPERIMENTO: {exp_name.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Tomar las top_n configuraciones\n",
    "        top_configs = results[:top_n]\n",
    "        \n",
    "        for i, config in enumerate(top_configs, 1):\n",
    "            metodo = config['metodo']\n",
    "            parametros = config['parametros']\n",
    "            silhouette = config['silhouette']\n",
    "            n_clusters = config['n_clusters']\n",
    "            modelo = config['modelo']\n",
    "            X_train = config['X_entrenamiento']\n",
    "            X_test = config['X_prueba']\n",
    "            labels_train = config['etiquetas_entrenamiento']\n",
    "            \n",
    "            print(f\"\\nTop {i}: {metodo} {parametros} (sil={silhouette:.4f}, n_clusters={n_clusters})\")\n",
    "            \n",
    "            # Crear figura con subplots\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            fig.suptitle(f'Top {i}: {metodo} {parametros}\\nSilhouette: {silhouette:.4f}, Clusters: {n_clusters}', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Aplicar PCA a los datos de entrenamiento\n",
    "            pca = PCA(n_components=2)\n",
    "            X_train_pca = pca.fit_transform(X_train)\n",
    "            \n",
    "            # Gráfico 1: Datos de entrenamiento con clusters\n",
    "            scatter1 = ax1.scatter(X_train_pca[:, 0], X_train_pca[:, 1], \n",
    "                                  c=labels_train, cmap='tab10', alpha=0.7, s=30)\n",
    "            ax1.set_title('Train (PCA 2D) - Clusters', fontweight='bold', pad=10)\n",
    "            ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} var.)')\n",
    "            ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} var.)')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Añadir colorbar para clusters\n",
    "            cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "            cbar1.set_label('Cluster', rotation=270, labelpad=15)\n",
    "            \n",
    "            # Gráfico 2: Datos de prueba con clusters asignados\n",
    "            # Predecir clusters en test\n",
    "            try:\n",
    "                if hasattr(modelo, 'predict'):\n",
    "                    pred_clusters_test = modelo.predict(X_test)\n",
    "                else:\n",
    "                    from sklearn.metrics import pairwise_distances_argmin_min\n",
    "                    if hasattr(modelo, 'cluster_centers_'):\n",
    "                        pred_clusters_test, _ = pairwise_distances_argmin_min(X_test, modelo.cluster_centers_)\n",
    "                    else:\n",
    "                        pred_clusters_test = np.array([-1] * len(X_test))\n",
    "            except:\n",
    "                pred_clusters_test = np.array([-1] * len(X_test))\n",
    "            \n",
    "            # Aplicar PCA a los datos de prueba (usando el mismo transformador de entrenamiento)\n",
    "            X_test_pca = pca.transform(X_test)\n",
    "            \n",
    "            scatter2 = ax2.scatter(X_test_pca[:, 0], X_test_pca[:, 1], \n",
    "                                  c=pred_clusters_test, cmap='tab10', alpha=0.7, s=30)\n",
    "            ax2.set_title('Test (PCA 2D) - Clusters Asignados', fontweight='bold', pad=10)\n",
    "            ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} var.)')\n",
    "            ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} var.)')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Añadir colorbar para clusters de test\n",
    "            cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "            cbar2.set_label('Cluster', rotation=270, labelpad=15)\n",
    "            \n",
    "            # Añadir información adicional\n",
    "            ax1.text(0.02, 0.98, f'Clusters: {n_clusters}', transform=ax1.transAxes, \n",
    "                    fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            ax2.text(0.02, 0.98, f'Clusters: {len(set(pred_clusters_test))}', transform=ax2.transAxes, \n",
    "                    fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Información adicional sobre la varianza explicada\n",
    "            print(f\"Varianza explicada por PC1: {pca.explained_variance_ratio_[0]:.4f} ({pca.explained_variance_ratio_[0]:.2%})\")\n",
    "            print(f\"Varianza explicada por PC2: {pca.explained_variance_ratio_[1]:.4f} ({pca.explained_variance_ratio_[1]:.2%})\")\n",
    "            print(f\"Varianza total explicada: {sum(pca.explained_variance_ratio_):.4f} ({sum(pca.explained_variance_ratio_):.2%})\")\n",
    "\n",
    "# Función adicional para gráficos de comparación de métodos\n",
    "def plot_cluster_comparison_pca(experiments):\n",
    "    \"\"\"Compara diferentes métodos en un solo gráfico PCA 2D\"\"\"\n",
    "    \n",
    "    # Tomar el mejor resultado de cada tipo de método\n",
    "    best_methods = {}\n",
    "    \n",
    "    for exp_name, results in experiments.items():\n",
    "        for result in results:\n",
    "            metodo = result['metodo']\n",
    "            if metodo not in best_methods or result['silhouette'] > best_methods[metodo]['silhouette']:\n",
    "                best_methods[metodo] = result\n",
    "    \n",
    "    # Crear gráfico comparativo\n",
    "    n_methods = len(best_methods)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Comparación de Métodos - Visualización PCA 2D', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (metodo, result) in enumerate(best_methods.items()):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        X_train = result['X_entrenamiento']\n",
    "        labels_train = result['etiquetas_entrenamiento']\n",
    "        silhouette = result['silhouette']\n",
    "        n_clusters = result['n_clusters']\n",
    "        \n",
    "        # Aplicar PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_train)\n",
    "        \n",
    "        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                           c=labels_train, cmap='tab10', alpha=0.7, s=20)\n",
    "        \n",
    "        # Título con información del método\n",
    "        metodo_corto = metodo.replace('KMeans-', 'KM-').replace('MiniBatch', 'MB')\n",
    "        ax.set_title(f'{metodo_corto}\\nSil: {silhouette:.3f}, Clusters: {n_clusters}', \n",
    "                    fontweight='bold', fontsize=11)\n",
    "        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Añadir colorbar\n",
    "        plt.colorbar(scatter, ax=ax)\n",
    "    \n",
    "    # Ocultar ejes vacíos\n",
    "    for idx in range(len(best_methods), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Función para análisis de densidad de clusters\n",
    "def plot_cluster_density_analysis(experiments):\n",
    "    \"\"\"Análisis de densidad y distribución de clusters\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle('Análisis de Densidad y Distribución de Clusters', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Gráfico 1: Distribución de tamaños de clusters por método\n",
    "    ax1.set_title('Distribución de Tamaños de Clusters por Método', fontweight='bold', pad=20)\n",
    "    \n",
    "    cluster_sizes_data = []\n",
    "    method_labels = []\n",
    "    \n",
    "    for exp_name, results in experiments.items():\n",
    "        for result in results[:5]:  # Tomar primeros 5 de cada experimento\n",
    "            metodo = result['metodo']\n",
    "            labels = result['etiquetas_entrenamiento']\n",
    "            \n",
    "            # Calcular tamaños de clusters\n",
    "            unique, counts = np.unique(labels, return_counts=True)\n",
    "            cluster_sizes_data.append(counts)\n",
    "            \n",
    "            # Etiqueta corta para el método\n",
    "            metodo_corto = metodo.replace('KMeans-', 'KM-').replace('MiniBatch', 'MB')\n",
    "            param_val = list(result['parametros'].values())[0]\n",
    "            method_labels.append(f\"{metodo_corto}\\n{param_val}\")\n",
    "    \n",
    "    # Boxplot de tamaños de clusters\n",
    "    boxplot = ax1.boxplot(cluster_sizes_data, labels=method_labels, patch_artist=True)\n",
    "    \n",
    "    # Colorear las cajas\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(cluster_sizes_data)))\n",
    "    for patch, color in zip(boxplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax1.set_ylabel('Tamaño del Cluster')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gráfico 2: Densidad de puntos por cluster (ejemplo con el mejor resultado)\n",
    "    ax2.set_title('Densidad de Puntos - Mejor Configuración', fontweight='bold', pad=20)\n",
    "    \n",
    "    # Encontrar el mejor resultado global\n",
    "    best_result = None\n",
    "    for exp_name, results in experiments.items():\n",
    "        for result in results:\n",
    "            if best_result is None or result['silhouette'] > best_result['silhouette']:\n",
    "                best_result = result\n",
    "    \n",
    "    if best_result:\n",
    "        X_train = best_result['X_entrenamiento']\n",
    "        labels = best_result['etiquetas_entrenamiento']\n",
    "        \n",
    "        # Aplicar PCA para visualización\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_train)\n",
    "        \n",
    "        # Crear scatter plot con densidad\n",
    "        scatter = ax2.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='tab10', alpha=0.6, s=20)\n",
    "        ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} var.)')\n",
    "        ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} var.)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Añadir colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax2)\n",
    "        cbar.set_label('Cluster', rotation=270, labelpad=15)\n",
    "        \n",
    "        # Añadir información\n",
    "        metodo = best_result['metodo']\n",
    "        silhouette = best_result['silhouette']\n",
    "        n_clusters = best_result['n_clusters']\n",
    "        ax2.text(0.02, 0.98, f'{metodo}\\nSil: {silhouette:.3f}\\nClusters: {n_clusters}', \n",
    "                transform=ax2.transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar los gráficos de PCA\n",
    "print(\"Generando gráficos de análisis PCA 2D...\")\n",
    "plot_pca_cluster_analysis(experiments, top_n=3)\n",
    "\n",
    "print(\"\\nGenerando comparación de métodos...\")\n",
    "plot_cluster_comparison_pca(experiments)\n",
    "\n",
    "print(\"\\nGenerando análisis de densidad...\")\n",
    "plot_cluster_density_analysis(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8758f",
   "metadata": {},
   "source": [
    "NOTA: Este bloque imprime todos los gráficos en un solo punto, por lo que si quieres visualizar de mejor forma los resultados, descomentar este bloque para visualizar los resultados anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38398c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Gráficos tradicionales para análisis de resultados\n",
    "\n",
    "def plot_improved_traditional_analysis(experiments):\n",
    "    \"\"\"Gráficos tradicionales mejorados para evitar solapamiento\"\"\"\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Análisis Comparativo de Algoritmos de Clustering', \n",
    "                 fontsize=16, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 1. TOP 8 Métodos por Silhouette (BARRAS HORIZONTALES para mejor legibilidad)\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Recolectar y ordenar métodos\n",
    "    all_results = []\n",
    "    for exp_name, results in experiments.items():\n",
    "        for result in results:\n",
    "            all_results.append(result)\n",
    "    \n",
    "    # Ordenar y tomar top 8\n",
    "    top_8 = sorted(all_results, key=lambda x: x['silhouette'], reverse=True)[:8]\n",
    "    \n",
    "    methods = []\n",
    "    silhouettes = []\n",
    "    \n",
    "    for result in top_8:\n",
    "        metodo = result['metodo']\n",
    "        param_val = list(result['parametros'].values())[0]\n",
    "        \n",
    "        # Nombres cortos y consistentes\n",
    "        if metodo == 'KMeans-random':\n",
    "            name = f\"KM-Rnd (k={param_val})\"\n",
    "        elif metodo == 'KMeans-++':\n",
    "            name = f\"KM++ (k={param_val})\"\n",
    "        elif metodo == 'MeanShift':\n",
    "            name = f\"MS (q={param_val})\"\n",
    "        elif metodo == 'MiniBatchKMeans':\n",
    "            name = f\"MB-KM (k={param_val})\"\n",
    "        elif metodo == 'DBSCAN':\n",
    "            name = \"DBSCAN\"\n",
    "        else:\n",
    "            name = f\"{metodo} ({param_val})\"\n",
    "            \n",
    "        methods.append(name)\n",
    "        silhouettes.append(result['silhouette'])\n",
    "    \n",
    "    # Gráfico de barras HORIZONTAL\n",
    "    y_pos = np.arange(len(methods))\n",
    "    bars = ax1.barh(y_pos, silhouettes, color='lightsteelblue', alpha=0.7, edgecolor='navy')\n",
    "    \n",
    "    ax1.set_title('A) Top 8 Configuraciones por Silhouette Score', fontweight='bold', pad=20)\n",
    "    ax1.set_xlabel('Silhouette Score')\n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(methods)\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar, val in zip(bars, silhouettes):\n",
    "        width = bar.get_width()\n",
    "        ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{val:.3f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # 2. Comparación ARI vs Silhouette (TOP 15 para claridad)\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    top_15 = sorted(all_results, key=lambda x: x['silhouette'], reverse=True)[:15]\n",
    "    sil_top = [r['silhouette'] for r in top_15]\n",
    "    ari_top = [r['ari'] for r in top_15]\n",
    "    methods_top = [r['metodo'] for r in top_15]\n",
    "    \n",
    "    # Colores y marcadores diferentes por método\n",
    "    color_map = {\n",
    "        'KMeans-random': ('red', 'o'),\n",
    "        'KMeans-++': ('blue', 's'), \n",
    "        'MeanShift': ('green', '^'),\n",
    "        'MiniBatchKMeans': ('orange', 'D'),\n",
    "        'DBSCAN': ('purple', 'v')\n",
    "    }\n",
    "    \n",
    "    for metodo in set(methods_top):\n",
    "        color, marker = color_map.get(metodo, ('gray', 'o'))\n",
    "        mask = [m == metodo for m in methods_top]\n",
    "        ax2.scatter(np.array(sil_top)[mask], np.array(ari_top)[mask], \n",
    "                   c=color, marker=marker, s=80, alpha=0.7, label=metodo, edgecolors='black')\n",
    "    \n",
    "    ax2.set_title('B) Relación: Silhouette vs ARI (Top 15)', fontweight='bold', pad=20)\n",
    "    ax2.set_xlabel('Silhouette Score')\n",
    "    ax2.set_ylabel('Adjusted Rand Index (ARI)')\n",
    "    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='ARI = 0 (aleatorio)')\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Métricas por Tipo de Algoritmo (promedios)\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    algorithm_data = {}\n",
    "    for result in all_results:\n",
    "        algo = result['metodo']\n",
    "        if algo not in algorithm_data:\n",
    "            algorithm_data[algo] = {'silhouette': [], 'ari': [], 'nmi': []}\n",
    "        algorithm_data[algo]['silhouette'].append(result['silhouette'])\n",
    "        algorithm_data[algo]['ari'].append(result['ari'])\n",
    "        algorithm_data[algo]['nmi'].append(result['nmi'])\n",
    "    \n",
    "    algorithms = list(algorithm_data.keys())\n",
    "    # Nombres cortos para algoritmos\n",
    "    algo_short = [algo.replace('KMeans-', 'KM-').replace('MiniBatch', 'MB') for algo in algorithms]\n",
    "    \n",
    "    avg_sil = [np.mean(algorithm_data[algo]['silhouette']) for algo in algorithms]\n",
    "    avg_ari = [np.mean(algorithm_data[algo]['ari']) for algo in algorithms]\n",
    "    avg_nmi = [np.mean(algorithm_data[algo]['nmi']) for algo in algorithms]\n",
    "    \n",
    "    x = np.arange(len(algorithms))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = ax3.bar(x - width, avg_sil, width, label='Silhouette', alpha=0.7, color='lightblue')\n",
    "    bars2 = ax3.bar(x, avg_ari, width, label='ARI', alpha=0.7, color='lightcoral')\n",
    "    bars3 = ax3.bar(x + width, avg_nmi, width, label='NMI', alpha=0.7, color='lightgreen')\n",
    "    \n",
    "    ax3.set_title('C) Métricas Promedio por Tipo de Algoritmo', fontweight='bold', pad=20)\n",
    "    ax3.set_xlabel('Algoritmo')\n",
    "    ax3.set_ylabel('Valor Promedio')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(algo_short, rotation=45)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Distribución de Número de Clusters Encontrados\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    cluster_counts = [r['n_clusters'] for r in all_results]\n",
    "    \n",
    "    # Histograma con KDE\n",
    "    n, bins, patches = ax4.hist(cluster_counts, bins=range(min(cluster_counts), max(cluster_counts)+2), \n",
    "                               alpha=0.7, color='mediumpurple', edgecolor='black', density=True)\n",
    "    \n",
    "    # Añadir línea de densidad\n",
    "    from scipy.stats import gaussian_kde\n",
    "    kde = gaussian_kde(cluster_counts)\n",
    "    x_range = np.linspace(min(cluster_counts), max(cluster_counts), 100)\n",
    "    ax4.plot(x_range, kde(x_range), color='darkblue', linewidth=2, label='Densidad')\n",
    "    \n",
    "    ax4.set_title('D) Distribución de Clusters Encontrados', fontweight='bold', pad=20)\n",
    "    ax4.set_xlabel('Número de Clusters')\n",
    "    ax4.set_ylabel('Densidad')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Añadir estadísticas\n",
    "    mean_clusters = np.mean(cluster_counts)\n",
    "    median_clusters = np.median(cluster_counts)\n",
    "    ax4.axvline(mean_clusters, color='red', linestyle='--', alpha=0.7, label=f'Media: {mean_clusters:.1f}')\n",
    "    ax4.axvline(median_clusters, color='orange', linestyle='--', alpha=0.7, label=f'Mediana: {median_clusters:.1f}')\n",
    "    ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecucion de gráficos \n",
    "print(\"Generando gráficos  tradicionales...\")\n",
    "plot_improved_traditional_analysis(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af4a83",
   "metadata": {},
   "source": [
    "\n",
    "## 13) Observaciones y conclusiones\n",
    "\n",
    "1. El dataset `hour.csv` tiene ~17,000 filas, cumpliendo el requisito de ≥10,000 filas.\n",
    "2. **Resultado central:** A pesar de que **MeanShift** obtuvo los mayores valores de Silhouette en varios casos (particiones geométricamente coherentes, sil≈0.4–0.5), las métricas que comparan clustering con la etiqueta `season` (ARI y NMI) son **prácticamente cero**, y la **accuracy** al asignar la etiqueta dominante por cluster ronda el baseline aleatorio (~0.25). Por tanto, **los clusters no representan la variable `season`**.\n",
    "\n",
    "3. **Efecto de features temporales:** Incluir `mnth` y `hr` facilita la recuperación de `season` (por correlación directa). Por eso se incluyó el experimento **without_time_features**. La comparación muestra que, aun quitando esos proxies, los clusters siguen sin alinearse con `season`.\n",
    "\n",
    "4. **Recomendación práctica:** Si el objetivo es **predecir `season`**, usar clustering no supervisado para asignar etiquetas **no** es una buena estrategia en este dataset. Recomendamos entrenar modelos supervisados (RandomForest/XGBoost) que aprovechen las señales para clasificación. Clustering puede ser útil para análisis exploratorio o para detectar subgrupos de demanda que no coinciden con estaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fa7b3-019a-4a4b-882e-7ab3c8cc26a5",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7a57a-3d41-491d-984c-5ff67e9985e6",
   "metadata": {},
   "source": [
    "#### Definición de Librerías e Instalación de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdc7bf-ab53-4c79-9200-4983604052bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0a78b-d293-4a61-9120-103cd044af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e587ff-335b-40b8-a273-4afb7ffcdea9",
   "metadata": {},
   "source": [
    "#### Carga y filtrado de Datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7475697-d43f-4a5a-9838-b6cabc3107a6",
   "metadata": {},
   "source": [
    "En el siguiente código se puede apreciar el dataset anteriormente utilizado, para empezar a trabajarlo y a utilizarlo para este apartado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966e0bd-9cbb-48a7-989a-2ef65b5666d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar Dataset\n",
    "dataset_id = \"1TL3UOc0VrUkN1cnvl1_YiTtOnU2NCMEO\"\n",
    "dataset_url = f\"https://drive.google.com/uc?id={dataset_id}&export=download\"\n",
    "dataset = pd.read_csv(dataset_url)\n",
    "\n",
    "# Muestreo de la tabla\n",
    "print(\"Dataset cargado:\")\n",
    "print(f\"Filas: {dataset.shape[0]}, Columnas: {dataset.shape[1]}\")\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a754583-fb40-48b1-b14c-103086f557b8",
   "metadata": {},
   "source": [
    "#### Definición de parámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76abe6c-4f2e-4d0d-9d0a-e86518bed881",
   "metadata": {},
   "source": [
    "En este apartado se definen las características (X) y la etiqueta en cuestión (Y) a través del siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f795c9-5f43-4d76-a07d-1c28f9869023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de X e Y \n",
    "X = dataset.drop(['season', 'dteday', 'casual', 'registered', 'cnt', 'instant'], axis=1) # Se consideran todos menos estos para X\n",
    "Y = dataset['season'] # Estaciones del año como etiqueta\n",
    "\n",
    "\n",
    "print(f\"Datos o características (X): {list(X.columns)}\")\n",
    "estaciones = {1: \"Invierno\", 2: \"Primavera\", 3: \"Verano\", 4: \"Otoño\"}\n",
    "print(f\"Etiqueta (Y): 'season' → {len(Y.unique())} clases: {[estaciones[x] for x in sorted(Y.unique())]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c758b-010b-469a-b6dc-987119df0b0a",
   "metadata": {},
   "source": [
    "Al ejecutar el código, se aprecia que las carácterísticas son todas menos las que tienen que ver con los datos de bicicletas. Estas se han obviado para analizar la posible estación del año **(season)** según los datos de temperatura, humedad, sensación térmica, etc, donde los datos de bicicletas no aportan nada para estas pretenciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a656f2a-3574-4c32-8509-89c0f7f27d86",
   "metadata": {},
   "source": [
    "#### Conjuntos de Entrenamiento y Testeo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f44d7a-3017-4196-bdc6-d195755e6061",
   "metadata": {},
   "source": [
    "Para entrenar los modelos, se tuvieron que definir conjuntos de entrenamiento y de testeo para cada parámetro (X e Y), con un porcentaje del 80% y el 20% para cada uno respectivamente. Para ello se realizó el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50d2a8-77b5-45e7-be12-e35de40ca92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de conjuntos de entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape[0]} registros\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape[0]} registros\")\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c5913-a109-417b-9279-584bd1a3b913",
   "metadata": {},
   "source": [
    "Posteriormente se escalaron los datos, algo necesario para que todas las características compitan en igualdad de condiciones y tengan la misma importancia en las predicciones, lo que asegura además mucha más estabilidad, haciendo que los algoritmos convergan mucho más rápido y obtener resultados mucho más confiables, ya que las predicciones no estarían sesgadas por la escala de los datos originales. Esto se realizó implementando lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363a462-0f2d-4e01-8c21-8e6ba593cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_escalado = scaler.fit_transform(X_train)\n",
    "X_test_escalado = scaler.transform(X_test)\n",
    "\n",
    "print(\"Datos escalados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea24d75-4524-4422-8a0d-559db6f690a5",
   "metadata": {},
   "source": [
    "#### Extracción externa de Hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1d435-ae97-4200-8d7e-21a19f784eb5",
   "metadata": {},
   "source": [
    "Este apartado consiste en extraer los datos de los hiperparámetros que serán utilizados para la configuración de los modelos de **regresión logística** y **SVM**, para ello se extrajeron del Drive público y se trabajaron de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105f463-6b9e-4bcf-bcc4-38696c4aff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_url = \"https://drive.google.com/uc?id=1TBoUlyd04czlwLWmow1du3oPEnNH_4PJ\"\n",
    "\n",
    "# Descarga y carga la configuración de drive\n",
    "response = requests.get(config_url)\n",
    "config = json.loads(response.text)\n",
    "\n",
    "print(\"Archivo de configuración cargado exitosamente\")\n",
    "print(f\"Configuraciones Logistic Regression: {len(config['logistic'])}\")\n",
    "print(f\"Configuraciones SVM: {len(config['svm'])}\")\n",
    "\n",
    "# Muestreo de Configuraciones para cada modelo\n",
    "print(\"\\nEjemplo de configuraciones:\")\n",
    "print(\"Configuraciones de Regresión Logística:\")\n",
    "for i, params in enumerate(config['logistic']):\n",
    "    print(f\"{params}\")\n",
    "    \n",
    "print(\"\")\n",
    "\n",
    "print(\"Configuraciones de SVM:\")\n",
    "for i, params in enumerate(config['svm']):\n",
    "    print(f\"{params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f2858-da4a-43d8-9e8e-b2b1cf065f26",
   "metadata": {},
   "source": [
    "Como se aprecia en el log de información, para cada algorítmo de clasificación se emplearon diversos hiperparámetros para variabilizar el entrenamiento y aprendizaje de los modelos, donde cada uno cumple las siguientes funciones:\n",
    "- **Hiperparámetro C**: Este componente reguraliza el balance en cuanto al ajuste de los datos de un modelo, es decir, funciona como Trade-off entre subajuste y sobreajuste para encontrar el valor óptimo para la adaptación según algún algoritmo en particular. Por ejemplo, si C tiene un valor pequeño, es posible que se subajuste bastante y el modelo contenga mucho ruido, no así si C tiene un valor alto, que tendería a sobreajustarse demasiado, memorizando más que aprendiendo de los patrones, por lo que fallaría bastante con los datos de testing. \n",
    "- **Hiperparámetro penalty**: Es el tipo de regularización que se aplica para la regresión logística, correspondiendo **l1** a Lasso y **l2** a Ridge. Lasso va eliminando características que considere irrelevantes y Ridge las mantiene todas pero con menos influencia en el modelo.\n",
    "- **Hiperparámetro solver**: Es el método de optimización que se utiliza en Regresión Logística para encontrar los mejores coeficientes.\n",
    "- **Hiperparámetro max_iter**: Como su nombre lo indica, es aquel componente que indica cuantas iteraciones se realizarán en total para cada configuración. Se utilizó la misma para todos los casos, para una comparación más justa y consistente entre configuraciones.\n",
    "- **Hiperparámetro kernel**: Es la función que permite a SVM separar datos complejos. El kernel **linear** solo puede crear divisiones rectas, mientras que **rbf** puede crear divisiones curvas para capturar patrones más complicados, siendo el más utilizado en la práctica por ser el que se adapta a la mayoría de datos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f52916-3262-405c-9613-a656449baf17",
   "metadata": {},
   "source": [
    "#### Función para el entrenamiento de modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609651d7-58ac-4b3b-a74c-8f88300902e9",
   "metadata": {},
   "source": [
    "En el siguiente apartado se apreciará cómo se realizan los entrenamientos para cada algoritmo con su configuración respectiva, esto a través de la configuración de la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67cf38-e469-4b66-881f-edb612e5a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_configuracion(info_modelo):\n",
    "    if info_modelo['tipo'] == \"logistic\":\n",
    "        modelo = LogisticRegression(**info_modelo['config'], random_state=42)\n",
    "    else:  # SVM\n",
    "        modelo = SVC(**info_modelo['config'], random_state=42)\n",
    "    \n",
    "    # Entrenamiento del modelo\n",
    "    modelo.fit(info_modelo['X_train'], info_modelo['y_train'])\n",
    "    \n",
    "    # Evaluación del entrenamiento en cuanto a las etiquetas\n",
    "    train_accuracy = modelo.score(info_modelo['X_train'], info_modelo['y_train'])\n",
    "    \n",
    "    return {\n",
    "        'tipo': info_modelo['tipo'],\n",
    "        'config': info_modelo['config'],\n",
    "        'modelo': modelo,\n",
    "        'accuracy_entrenamiento': train_accuracy,\n",
    "        'id': info_modelo['id'],\n",
    "        'exitoso': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a1945-1ac4-4d4e-901d-13569eb2d6ac",
   "metadata": {},
   "source": [
    "Esta función primero define los modelos con sus respectivos hiperparámetros a utilizar, ya sea para **LogisticRegression** o **SVM** (SVC en el caso de la codificación de este algorítmo), para luego realizar el entrenamiento y adaptación de los datos utilizando **.fit** pasándole el conjunto de datos de entrenamiento de por medio (para X e y). Además de eso, se realiza la evaluación del entrenamiento del modelo con **.score** paara apreciar el grado de acierto con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d4d33-1b1d-47cc-9fa5-8b5948481b9f",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d575f0b-06e4-46c6-85ae-5416241ac1c9",
   "metadata": {},
   "source": [
    "Empleando la función anterior, se configuró el siguiente código donde se realizaron los entrenamientos a través de épocas, siendo un total de 15 repeticiomnes en las que se realizaría el entrenamiento con las configuraciones de ambos algorítmos.\n",
    "\n",
    "Este consiste en crear toda las configuraciones a entrenar, ya sea de regresión logística o SVM, para posteriormente iniciar el entrenamiento por época. Al iniciar la primera época, ejecuta las 8 configuraciones posibles de los algorítmos de manera paralela, permitiendo que se realice de una manera más rápida la ejecución del código, para además ejecutar el llamado de la función **entrenar_configuracion** descrita anteriormente, pasándole el tipo de configuración con sus parámetros respectivos. Luego filtra si el modelo fue exitoso, en relación a si pudo realizarse y terminar de ejecutarse, copiando esos resultados. Posteriormente, se realiza la eliminación de la configuración con el peor rendimiento cada 5 épocas dentro del código, eliminándose 3 de las 8 posibles.\n",
    "\n",
    "Al terminar el ciclo de las 15 épocas, se imprime el Ranking completo de las configuraciones y se evalua cada uno con el conjunto de prueba o **testing** para comparar su porcentaje de éxito en cuanto a la precisión real de los modelos entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffa268-16b5-46ef-87ad-7cdd55a340bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque de código que \n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Crea todas las configuraciones a entrenar\n",
    "modelos_a_entrenar = []\n",
    "model_id = 0\n",
    "\n",
    "# Configuraciones de Regresión Logística\n",
    "for lr_config in config['logistic']:\n",
    "    modelos_a_entrenar.append({\n",
    "        'tipo': 'logistic',\n",
    "        'config': lr_config,\n",
    "        'X_train': X_train_escalado,\n",
    "        'y_train': y_train,\n",
    "        'id': model_id\n",
    "    })\n",
    "    model_id += 1\n",
    "\n",
    "# Configuraciones de SVM\n",
    "for svm_config in config['svm']:\n",
    "    modelos_a_entrenar.append({\n",
    "        'tipo': 'svm',\n",
    "        'config': svm_config,\n",
    "        'X_train': X_train_escalado,\n",
    "        'y_train': y_train,\n",
    "        'id': model_id\n",
    "    })\n",
    "    model_id += 1\n",
    "\n",
    "print(f\"Iniciando con {len(modelos_a_entrenar)} configuraciones totales\")\n",
    "\n",
    "# Entrenamiento por épocas con eliminación cada 5 épocas\n",
    "modelos_activos = modelos_a_entrenar.copy()\n",
    "resultados_finales = []\n",
    "total_epocas = 15\n",
    "\n",
    "for epoca in range(total_epocas):\n",
    "    print(f\"\\nÉpoca {epoca + 1}/{total_epocas}\")\n",
    "    \n",
    "    # Entrenamiento paralelo\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        resultados_epoca = list(executor.map(entrenar_configuracion, modelos_activos))\n",
    "    \n",
    "    # Filtra los modelos exitosos\n",
    "    modelos_exitosos = [r for r in resultados_epoca if r['exitoso']]\n",
    "    resultados_finales = modelos_exitosos.copy()\n",
    "    \n",
    "    print(f\"Modelos exitosos: {len(modelos_exitosos)}\")\n",
    "    \n",
    "    # Elimina la peor configuración cada 5 épocas\n",
    "    if (epoca + 1) % 5 == 0 and len(modelos_exitosos) > 2:\n",
    "        modelos_exitosos.sort(key=lambda x: x['accuracy_entrenamiento'], reverse=True)\n",
    "        peor_modelo = modelos_exitosos.pop()\n",
    "        \n",
    "        print(f\"Eliminado en la época {epoca + 1}:\")\n",
    "        print(f\"- Tipo: {peor_modelo['tipo']}\")\n",
    "        print(f\"- Configuración: {peor_modelo['config']}\")\n",
    "        print(f\"- Precisión: {peor_modelo['accuracy_entrenamiento']:.4f}\")\n",
    "    \n",
    "    # Prepara los modelos para la siguiente época\n",
    "    modelos_activos = [\n",
    "        {\n",
    "            'tipo': m['tipo'], \n",
    "            'config': m['config'], \n",
    "            'X_train': X_train_escalado, \n",
    "            'y_train': y_train, \n",
    "            'id': i\n",
    "        }\n",
    "        for i, m in enumerate(modelos_exitosos)\n",
    "    ]\n",
    "\n",
    "print(f\"\\nEntrenamiento completado. Modelos finales: {len(resultados_finales)}\")\n",
    "\n",
    "# Muestra todas configuraciones ordenadas y enumeradas \n",
    "print(\"Ranking Completo de las Configuraciones\")\n",
    "\n",
    "resultados_finales.sort(key=lambda x: x['accuracy_entrenamiento'], reverse=True)\n",
    "\n",
    "for i, resultado in enumerate(resultados_finales, 1):\n",
    "    print(f\"\\n#{i} - {resultado['tipo'].upper()} - Precisión: {resultado['accuracy_entrenamiento']:.4f}\")\n",
    "    print(f\"- Configuración: {resultado['config']}\")\n",
    "    \n",
    "    # Evalua en TEST para todas configuraciones\n",
    "    modelo = resultado['modelo']\n",
    "    y_pred_test = modelo.predict(X_test_escalado)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"- Precisión del Test: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Imprime el TOP 2 de las mejores configuraciones con mayor precisión\n",
    "    if i <= 2:\n",
    "        print(f\"- TOP {i} mejores Configuraciones\")\n",
    "        # \n",
    "        top_2_modelos = sorted(resultados_finales, key=lambda x: x['accuracy_entrenamiento'], reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a010a2e-c25e-4f32-94d6-09a9fe81e22d",
   "metadata": {},
   "source": [
    "Se puede observar que el mejor desempeño dentro de las configuraciones fue obtenido por **SVM** con kernel RBF y C=10, logrando un 95.9% de precisión en entrenamiento y 94.2% en prueba. Esta mínima diferencia (solo 1.7%) indica que el modelo esta bien balanceado, sin sobreajuste significativo, capaz de generalizar efectivamente frente a datos o combinación de datos que no conocía."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d2a22-b60b-445a-8efb-dcc8e88d927d",
   "metadata": {},
   "source": [
    "#### Gráficos de Matriz de Confusión y Precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a7f32-7948-4f0b-afad-541889ae18da",
   "metadata": {},
   "source": [
    "Para finalizar, se generaron gráficos específicos para los mejores modelos, permitiendo comprender detalladamente su comportamiento:\n",
    "- **Matriz de Confusión:** Es una matriz que permite visualizar no solamente los aciertos, sino también los errores que se puedan presentar. La diagonal de la matriz representa el numero de aciertos y los valores externos son los errores que se presentan en el modelo.\n",
    "- **Comparación de precisión:** Se implementó un gráfico de barras comparativo que contrasta el rendimiento en relación a la precisión de las configuraciones, tanto para los modelos entrenados como para los evaluados con datos de prueba.\n",
    "\n",
    "Todo esto se realizó a través del siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b20c77-1cbc-4646-b318-b45bd1af6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de estilos de gráficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear figura con subgráficos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('GRÁFICOS DE LAS 2 MEJORES CONFIGURACIONES', fontsize=16, fontweight='bold')\n",
    "\n",
    "estaciones = {1: \"Invierno\", 2: \"Primavera\", 3: \"Verano\", 4: \"Otoño\"}\n",
    "nombres_estaciones = [estaciones[i] for i in sorted(estaciones.keys())]\n",
    "\n",
    "for i, resultado in enumerate(top_2_modelos):\n",
    "    modelo = resultado['modelo']\n",
    "    y_pred_test = modelo.predict(X_test_escalado)\n",
    "    \n",
    "    # Gráfico 1: Matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=nombres_estaciones,\n",
    "                yticklabels=nombres_estaciones,\n",
    "                ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{resultado[\"tipo\"].upper()} - Matriz de Confusión\\nConfig: {resultado[\"config\"]}')\n",
    "    axes[i, 0].set_xlabel('Predicción')\n",
    "    axes[i, 0].set_ylabel('Real')\n",
    "    \n",
    "    # Gráfico 2: Comparación de Precisión vs Entrenamiento/Test\n",
    "    metricas = ['Entrenamiento', 'Test']\n",
    "    valores = [resultado['accuracy_entrenamiento'], accuracy_score(y_test, y_pred_test)]\n",
    "    \n",
    "    bars = axes[i, 1].bar(metricas, valores, color=['skyblue', 'lightcoral'])\n",
    "    axes[i, 1].set_title(f'{resultado[\"tipo\"].upper()} - Comparación de Accuracy')\n",
    "    axes[i, 1].set_ylabel('Precisión')\n",
    "    axes[i, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for bar, valor in zip(bars, valores):\n",
    "        height = bar.get_height()\n",
    "        axes[i, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                       f'{valor:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e765f6b-7b77-4cc4-84f8-d04ab2938227",
   "metadata": {},
   "source": [
    "Los gráficos generados validan consistentemente el alto rendimiento de la mejor configuración de **SVM**, mostrando en su matriz de confusión una diagonal con un azulado muy intenso, lo que indica un alto volumen de predicciones correctas para todas las estaciones. Además, el modelo alcanzó un **95,91% de precisión en entrenamiento** y mantuvo **94,22% en prueba**, demostrando una gran capacidad de generalización con con una mínima diferencia entre ambos conjuntos. \n",
    "\n",
    "Con los segundos gráficos, se aprecia una gran diferencia en cuanto al mejor modelo, teniendo un 10% menos de precisión en comparación al más óptimo. Además, se distinguen una gran cantidad de errores en la matriz de confusión, siendo la principal razón de estos los valores de los hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd585b3-5642-466d-ac8e-78c59bdd745b",
   "metadata": {},
   "source": [
    "## Observaciones y Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2def4-fc5d-4792-88ee-333bf4e65e77",
   "metadata": {},
   "source": [
    "En base a la Regresión Logística y SVM, se puede apreciar que según la manera en que se realice el entrenamiento y los hiperparámetros que se empleen para aquello, se va a acoplar de mejor o peor manera a los datos para cada modelo. Esto se apreció tanto por la eliminación mediante épocas como por los gráficos finales de las mejores configuraciones de ambos algorítmos.\n",
    "\n",
    "Es fundamental probar e ir iterando hasta encontrar mediante la convergencia, un modelo adecuado para la predicción y el acercamiento a la etiqueta 'Y', siendo de vital importancia la definición que uno le puede dar a cada algóritmo de manera previa.\n",
    "\n",
    "Además, nos pudimos percatar del potencial que poseían estos modelos para la clasificación y su gran índice de precisión, lo que demuestra la efectividad de los algoritmos SVM y Regresión Logística para problemas de clasificación multiclase, particularmente cuando se combinan con técnicas avanzadas de preprocesamiento y entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
